---
layout: post
title: ML: paper translation
date: 2020-10-04
tags: GNN
---


# Gravity-Inspired Graph Autoencoders for Directed Link Prediction  
# 针对链路预测的重力启发式图自编码器  
**作者：Guillaume Salha， Stratis Limnios， Romain Hennequin， Viet Anh Tran， Michalis Vazirgiannis.  **  
## 摘要  
图自动编码器（AE）和变分自动编码器（VAE）最近作为强大的节点嵌入方法出现了。 特别是，图AE和VAE被成功地利用来解决具有挑战性的链接预测问题，旨在弄清楚图中的某些节点对是否通过未观察到的边连接。 但是，这些模型专注于无向图，因此忽略了链接的潜在方向，这限制了许多实际应用。 在本文中，我们扩展了图AE和VAE框架，以解决有向图中的链接预测。 我们提出了一种新的重力启发式解码器方案，该方案可以从节点嵌入中有效地重构有向图。 我们对三种不同的有向链接预测任务进行经验评估，这些任务的标准图AE和VAE效果较差。 我们在三个真实世界的图表上取得了竞争性结果，超过了一些流行的基准。  
## CCS CONCEPTS  
• Information systems → Social networks;   
• Mathematics of computing → Graph algorithms;   
• Computing methodologies → Learning latent representations.

## 关键字  
有向图，自动编码器，变分自动编码器，图表示学习，节点嵌入，链接预测  
## 1. 介绍  
图形是有用的数据结构，可以有效地表示项目之间的关系。 由于图形数据的激增[54，56]，各种各样的特定问题引发了机器学习社区的重大研究工作，旨在从此类结构中提取相关信息。 这包括节点聚类[33]，影响最大化[21]，图生成[45]和链接预测，这是我们在本文中关注的重点。  

链接预测关键在于根据可观察的链接及其属性[29，52]推断实体对（节点）之间是否存在新的关系或仍未观察到的交互（即，图中的新边）。 这一具有挑战性的任务已得到广泛研究，并成功应用于多个领域。 在生物网络中，利用链接预测模型来预测蛋白质之间的新相互作用[26]。 它也存在于我们的日常生活中，暗示我们的社交网络中可能认识的人，但我们仍然没有联系[18、29、52]。 此外，链接预测与众多推荐任务密切相关[4、28、58]。

链接预测在历史上已通过图挖掘启发式法，通过在节点之间构建相似性索引来解决，从而捕获了它们在图中的连接可能性。反映邻域结构和节点接近度的Adamic-Adar和Katz索引[29]是此类相似性索引的臭名昭著的例子。最近，随着将深度学习方法扩展到图结构[6、43、54]的努力越来越多，这些方法已被节点嵌入范式[16、46、56]超越。概括地说，该策略是训练图神经网络将节点表示为低维向量空间（即嵌入空间）中的向量。理想情况下，在此类空间中，图中的结构接近的节点应彼此靠近。因此，人们可以求助于诸如矢量表示之间的内积之类的接近性度量，以预测基础图中的新未观察到的链接。在这个方向上，自动编码器（AE）[1，40]和变分自动编码器（VAE）[23，48]的图形扩展最近在许多实验分析中作为最新的链接预测方法出现[25，38] ，41，47，51]。

但是，这些模型专注于无向图，因此忽略了链接的潜在方向。如第2节所述，预测节点i连接到节点j的图形自动编码器也将以相同的概率预测节点j连接到节点i。由于有向图无处不在，因此这限制了许多实际应用。例如，网络图由有向超链接组成。在诸如Twitter之类的社交网络中，舆论领袖通常被许多用户关注，但是这些联系中只有单项 很少的是互惠的。此外，有向图是在许多没有将数据显式构造为图的领域中的有效抽象。例如，在音乐流媒体平台上，提供有关歌手的信息的页面通常将显示k个最相似的歌手。艺术家的相似性可以在一个图中表示，其中的节点是艺术家，与他们的k个最相似的邻居相连。这样的图绝对是有针对性的：的确，尽管鲍勃·马利可能是一个新的未知雷鬼乐队中最相似的艺术家之一，但该乐队不太可能出现在鲍勃·马利页面上的顶级相似艺术家中。

定向链接预测已通过图挖掘非对称度量得到解决[13、44、55]，最近，有人提出了在创建节点嵌入时捕获非对称接近度的一些尝试[34、36、59]。 但是，如何从向量空间表示中重建有向图以有效执行有向链接预测的问题仍然广泛存在。 特别是，尚不清楚如何将图AE和图VAE扩展到有向图，以及在有向链接预测任务上还可以在何种程度上实现这些模型在无向图上的有前途的性能。 我们建议解决这些问题
在本文中，做出了以下贡献：  

• 我们提出了一种新模型，可以使用图AE和VAE框架从有向图中有效地学习节点嵌入。 我们从牛顿的万有引力理论中汲取灵感，介绍了一种新的解码器方案，该方案能够从矢量空间节点嵌入中重建不对称关系。  

• 我们对三种不同的有向链接预测任务进行经验评估，这些任务的标准图AE和VAE效果较差。 我们在三个现实世界的数据集上取得了竞争性结果，超过了流行基准。 据我们所知，这是有向图上的第一个图AE / VAE实验。 

• 我们为这些实验公开发布了code1，以提高可重复性并简化将来的使用。  

本文的组织如下。 在第2节中，我们回顾了与图AE和VAE相关的关键概念，并解释了为什么这些模型不适合定向链接预测。 在第3节中，我们介绍了重力启发方法，以使用图AE或VAE重建有向图，并有效执行有向链接预测。 我们在第4节中介绍和讨论我们的实验分析，在第5节中总结。  

## 准备工作/前情回顾

在本节中，我们概述了图AE，VAE及其在链接预测中的主要应用。 在下面，我们考虑具有| V |的无自环图G =（V，E）。 = n个节点，| E | =可以定向的m条边。 我们用A表示G的邻接矩阵，该矩阵是二进制的或加权的。 此外，节点可能具有大小为f的特征向量，并聚集在n×f矩阵X中。否则，X为n×n恒等式 ***I***。

### 2.1 图自编码器 GAE

图自动编码器[25，51]是将自动编码器[1，40]扩展到图结构的一系列无监督模型。 他们的目标是学习节点嵌入，即节点的低维向量空间表示。 图AE由两个堆叠模型组成：

 • 首先，编码器模型为图中的每个节点i分配大小为d且大小的潜矢量zi。 所有潜在向量zi的n×d矩阵Z通常是图神经网络（GNN）的输出，该图神经网络适用于A，并在适当时应用于X，即Z = GNN（A，X）。


 • 然后，解码器模型旨在使用另一个GNN或更简单的替代方法从Z重建邻接矩阵A。 例如，在[25]及其模型的[38，41]的几个扩展中，解码是通过潜在矢量之间的内积以及S型激活σ（x）= 1 /（1 + e-x）获得的。 或者，如果对A加权，则进行一些更复杂的阈值处理。 换句话说，内积zTizj越大，根据模型在图中连接的节点i和j的可能性就越大。 从解码器表示Aˆ A的重建，我们有Aˆ =σ（ZZT）。   

自动编码器背后的直觉如下：如果从潜矢量开始，解码器能够重建与原始矢量接近的邻接矩阵Aˆ，则这意味着这些表示保留了图结构的某些重要特征。 通过最小化图结构的重建损失∥A-Aˆ∥F [51]，用F·Robinius矩阵范数∥·∥F，或者通过梯度下降[15]，加权交叉熵损失[25]来训练图AE。 。

### 2.2 图卷积神经网络 GCN

在整个论文中，作为[25]和大多数后续工作[10、17、38、41]，我们假设GNN编码器是图卷积网络（GCN）[24]。 在GCN中有L层，L≥2且Z = H（L），我们有：

<img src="https://github.com/QUAFFquaff/picture_for_md/blob/master/GAE/pic1.jpg?raw=true" width = "550" height = "300" alt="Structure" align=center />  

在上述等式中，A〜表示A的某些归一化形式。由于在现有模型中考虑了无向图，因此通常的选择是对称归一化A〜= D -1/2（A + I）D -1/2，其中 D是A + I的对角度矩阵。 简而言之，对于每个layerl，我们对给定节点的邻居的H（l-1）的特征向量，其自身的特征信息（因此为I）和ReLU激活进行平均：ReLU（x）= max（x，0）。 权重矩阵W（l）通过随机梯度下降训练

我们依赖GCN编码器的原因主要有以下三个：1）与以前在图AE方面所做的努力保持一致； 2）在基于GCN的图AE之前获得成功的情况下采用大写形式（请参阅第2.4小节），最后但并非最不重要的是3）提高了计算效率。 实际上，评估GCN的每一层都具有线性复杂度w.r.t。 边数m [24]。 还提出了提高GCN训练速度的策略[8，53]。 尽管如此，我们指出，本文中介绍的方法不限于GCN，对于任何其他编码器（例如， 对于更复杂的编码器，例如ChebNet [9]，有时在经验上优于GCN编码器[41]。  
G
### 2.3 图变分自编码器 VGAE

[25]引入了变图自动编码器，表示为VGAE，是VAE的图形扩展[23]。 在共享自动编码器名称的同时，VAE实际上是基于完全不同的数学基础。具体而言，[25]假设图上的概率模型涉及每个节点i∈V的长度为d≪ n的潜在变量zi。 这样的向量是低维嵌入空间Z中的节点表示。作者用Z表示所有潜在向量的n×d矩阵，作者将推理模型定义如下：

<img src="https://github.com/QUAFFquaff/picture_for_md/blob/master/GAE/pic2.jpg?raw=true" width = "600" height = "200" alt="Structure" align=center />  


潜矢量zi本身是从学习到的分布中提取的随机样本，该推断步骤称为图形VAE的编码部分。 使用两个GCN来学习高斯分布的参数。 换句话说，平均矢量矩阵μi的定义为μ=GCNμ（A，X）。 同样，logσ=GCNσ（A，X）。

然后，一个生成模型尝试使用潜在变量之间的内积来重建A，例如图AE： 

<img src="https://github.com/QUAFFquaff/picture_for_md/blob/master/GAE/pic3.jpg?raw=true" width = "600" height = "150" alt="Structure" align=center />  
如前所述，σ（·）是S型激活函数。 这是模型的解码部分。 [25]通过最大化模型可能性的可预测变化下界（ELBO）来优化GCN权重：  
<img src="https://github.com/QUAFFquaff/picture_for_md/blob/master/GAE/pic4.jpg?raw=true" width = "600" height = "150" alt="Structure" align=center /> 

高斯先验p（Z）=Îp（zi）=ÎN（zi | 0，I），使用整批梯度下降并利用重新参数化技巧[23]。 DK L（·，·）是Kullback-Leibler散度[27]。

### 2.4 对于无向链接得GAE和VAE

在过去的三年中，图AE / VAE及其扩展已经成功地用于解决一些挑战性任务，例如节点聚类[38、41、50]，二部图的推荐[4、10]和图生成，尤其是生物学上 从图VAE的生成模型中得出合理的分子生成[19，30,31，42，45]。 我们参考前面提到的参考资料，对这些应用程序进行更广泛的概述，并在本节的其余部分重点介绍链接预测任务。  

在[25]的开创性工作和众多扩展[17，38，41，47]中，链接预测一直是图AE和VAE的主要评估任务。简而言之，作者使用节点的潜在空间表示，评估了其模型的整体能力，以预测无向图中的几对节点是否通过未观察到的边连接。更正式地说，在这种设置中，通常会在图形的不完整版本上训练自动编码器，在该版本中，会随机删除一部分边缘（例如10％）。然后，创建一个测试集，收集这些缺失的边缘和相同数量的随机选择的未连接节点对。作者评估模型通过使用潜在向量Aˆi，j =σ（zTizj）的解码来区分真实边缘（即完整邻接矩阵中的Aij = 1）与假边缘（Aij = 0）的能力。预测当Aˆi，jis大于某个阈值时节点已连接。这是一个二进制分类任务，通常使用接收器工作特征（ROC）曲线下的面积（AUC）或平均精度（AP）分数进行评估。对于此类任务，经验证明AE和VAE图表具有竞争力，并且通常比W.r.t.一些流行的节点嵌入基准，特别是Laplacian特征图[3]和类似于word2vec的模型，例如DeepWalk [39]，LINE [46]和node2vec [16]。

我们指出，这些实验大多数都集中在具有多达数千个节点和边的中等大小的图上，这主要是由于内积解码器的O（dn2）二次时间复杂度有限所致，其中涉及到密集矩阵Z和ZT然而，[41]最近绕过了这个可伸缩性问题，并利用图简并性概念[32]引入了用于可伸缩性图AE和VAE的通用框架。他们基于对多达数百万个节点和边的无向图的实验，证实了图AE和VAE在大规模链接预测方面的竞争性能。

### 2.5 为什么这些模型在有向图得表现不好？  

在此阶段，我们记得前面提到的所有工作都明确或隐含地假定输入图是无向的。 通过设计，图AE和VAE不适合有向图，因为它们在从嵌入中重建邻接矩阵时会忽略方向。 实际上，由于内积解码器的对称性，我们具有： 

<img src="https://github.com/QUAFFquaff/picture_for_md/blob/master/GAE/pic5.jpg?raw=true" width = "600" height = "150" alt="Structure" align=center /> 

换句话说，如果我们预测从节点i到节点j的边缘（i，j）的存在，那么我们也必须以相同的概率预测反向边缘（j，i）的存在。 结果，正如我们在第4节中的经验所示，标准图AE和VAE在有向图中的链接预测任务上表现明显不佳，这些关系之间的关系并不总是互惠的。  

将内积解码器替换为嵌入中的Lp距离（例如，如果p = 2，则为欧几里德距离）或使用现有的更精细的解码器方案[17]会得出相同的结论，因为它们也是对称的。 最近，[57]提出了D-VAE，一种用于小型有向无环图（DAG）的变体自动编码器，例如神经网络体系结构或贝叶斯网络，其重点是神经体系结构搜索和结构学习。 但是，如何将图AE和VAE扩展到一般有向图，例如在有向链接预测很有挑战的引文网络或Web超链接网络中，仍然存在问题

### 2.6 关于源/目标向量范式


## 3 一个针对有向图得重力启发式GAE & VAE

在本节中，我们将介绍一个新模型，以使用AE和VAE框架从有向图中学习节点嵌入，并解决有向链接预测问题。 主要挑战如下：如何从编码表示形式（内积和标准距离对称的节点嵌入中）中的（唯一）潜矢量有效地重构非对称关系？

为了克服这一挑战，我们诉诸于经典力学，尤其是牛顿的万有引力理论。 我们提出了一个嵌入中的潜在节点表示与空间中的天体之间的类比。 具体而言，即使地月距离是对称的，由于重力，月球向地球的加速度也比地向月球的加速度大。 如下所述，这是因为地球更大。 在本节的其余部分中，我们将质量和加速度的这些概念转换为节点嵌入，以构建我们的非对称图解码方案。

### 3.1 牛顿的万有引力理论


### 3.2 从物理到节点 

让我们回到在空间中的天体与节点嵌入之间的最初类比。 在本小节中，让我们假设，除了维数为d≪的潜矢量zi之外，我们还有一个模型可以为每个节点i∈V学习新的质量参数mi∈R +。 这样的参数将捕获i的倾向，以便吸引该图中其他节点的其他节点，即使其通过有向边指向i。 从这种扩充模型中，我们可以在生成的嵌入中应用牛顿方程。 具体来说，我们可以将节点i由于嵌入中的重力而朝向节点j的加速度$ai→j = Gmj/r^{2}$作有向图中i与j连接的可能性的指标，其中  
$$r^{2} = \parallel zi-zj\parallel ^{2}_{2}$$  简而言之

- 分子捕捉到以下事实：某些节点比图中的其他节点更有影响力。 例如，在科学出版物的引文网络中，开创性的开篇文章更具影响力，应予以更多引用。 在此，mj越大，我越有可能通过（i，j）有向边连接到j。

- 分母突出显示，如果模型有效地设法将这些节点彼此靠近地嵌入潜在空间表示中，则图中具有结构邻近性的节点（通常具有公共邻域）更可能被连接。 例如，在科学出版物引文网络中，如果文章i来自类似的研究领域，则文章i更可能引用文章j。